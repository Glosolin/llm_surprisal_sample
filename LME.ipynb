{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear-Mixed Effects Model to Evaluate the Impact of Sampling Methods on Human Reading Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Background:   \n",
    "Recent findings show that larger and more accurate language models like\n",
    "GPT-2, despite having lower perplexity, generates surprisal estimates that are not as effective in predicting human reading times and eye-gaze durations, challenging the “larger is better” trend in NLP.  \n",
    "\n",
    "The objective of our project is to investigate the underlying causes of the diminished accuracy in predicting human reading times by more complex language models.  We hypothesize that appropriate **sampling methods** could potentially enhance the large language models’ performance in surprisal study, because sampling methods, such as top-k sampling, is implemented by zeroing out the probabilities for tokens below the k-th one, which will re-weight token logits (used\n",
    "to calculate surprisal estimates) by removing noise. \n",
    "\n",
    "Our study is particularly focused on assessing whether the sampling methodologies influence the efficacy of the advanced language models in accurately predicting human reading times.\n",
    "\n",
    "Authors: Meiyu (Emily) Li, Yuwen Shen, Tongyu Zhao, Zehui (Bella) Gu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LME models and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_surp(df, df_surp):\n",
    "    df_copy = df.copy()  \n",
    "    df_copy['llm_surp'] = 0\n",
    "    start_row = 0\n",
    "    llmsurp_list = df_surp['llm_surp'].tolist()\n",
    "    size_list = df_copy.groupby(['sentid', 'sentpos']).size().tolist()\n",
    "\n",
    "    assert len(size_list) == len(df_surp)\n",
    "    \n",
    "    for i in range(len(df_surp)):\n",
    "        df_copy.loc[start_row:start_row + size_list[i]-1, 'llm_surp'] = llmsurp_list[i]\n",
    "        start_row = start_row + size_list[i]\n",
    "\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preporcess(data):\n",
    "    data['id'] = data.index\n",
    "    data = data[data['sentpos'] != 1]\n",
    "    ids = np.array([])\n",
    "    last_sentpos_for_each_sent = data.groupby('sentid')['sentpos'].max().tolist()\n",
    "    sentid_list = data['sentid'].unique().tolist()\n",
    "\n",
    "    for i in range(len(last_sentpos_for_each_sent)):\n",
    "        temp_data = data[data['sentid'] == sentid_list[i]]\n",
    "        temp_id = temp_data[temp_data['sentpos'] == last_sentpos_for_each_sent[i]]['id'].tolist()\n",
    "        ids = np.append(ids, temp_id)\n",
    "\n",
    "    data = data[~data['id'].isin(ids)]\n",
    "    data = data[data['correct'] >= 4]\n",
    "    data = data[(data['WorkTimeInSeconds'] > 100) & (data['WorkTimeInSeconds'] < 3000)]\n",
    "\n",
    "    # log_transform\n",
    "    cols1 = ['wlen', 'sentpos', 'llm_surp', 'fdur']\n",
    "    for col in cols1:\n",
    "        if col in data.columns:\n",
    "            data[col] = np.log(data[col]+1)\n",
    "    # scale\n",
    "    scaler = StandardScaler()\n",
    "    predictors = ['wlen', 'sentpos', 'llm_surp', 'fdur']\n",
    "    predictors = [col for col in predictors if col in data.columns]\n",
    "    data[predictors] = scaler.fit_transform(data[predictors])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model1, method1, model2, method2):\n",
    "    raw_data = pd.read_csv('data/naturalstories.evmeasures', header = 0, sep = \" \")\n",
    "    surp1 = pd.read_csv(f'naturalstories.{model1}.{method1}.surprisal', header = 0, sep = \" \", encoding = 'utf-16')\n",
    "    surp2 = pd.read_csv(f'naturalstories.{model2}.{method2}.surprisal', header = 0, sep = \" \", encoding = 'utf-16')\n",
    "    \n",
    "    data1 = combine_surp(raw_data, surp1)\n",
    "    data2 = combine_surp(raw_data, surp2)\n",
    "    data1 = preporcess(data1)\n",
    "    data2 = preporcess(data2)\n",
    "    print('Finish processing data!')\n",
    "    \n",
    "    baseline = smf.mixedlm(\"fdur ~ wlen + sentpos\", data=data1, groups=data1[\"subject\"])\n",
    "    baseline = baseline.fit()\n",
    "    ll_baseline = baseline.llf\n",
    "    # print('Baseline: ')\n",
    "    # print(baseline.summary())\n",
    "\n",
    "    lme1 = smf.mixedlm(\"fdur ~ wlen + sentpos + llm_surp\", data=data1, groups=data1[\"subject\"])\n",
    "    lme1 = lme1.fit()\n",
    "    ll_model1 = lme1.llf\n",
    "    # print(f'\\n{model1}: ')\n",
    "    # print(lme1.summary())\n",
    "\n",
    "    lme2 = smf.mixedlm(\"fdur ~ wlen + sentpos + llm_surp\", data=data2, groups=data2[\"subject\"])\n",
    "    lme2 = lme2.fit()\n",
    "    ll_model2 = lme2.llf\n",
    "    # print(f'\\n{model2}: ')\n",
    "    # print(lme2.summary())\n",
    "\n",
    "    # print out the improvement of each model (with llm_surp) with respect to the baseline\n",
    "    print(f'{model1}_{method1}: ', ll_model1 - ll_baseline)\n",
    "    print(f'{model2}_{method2}: ', ll_model2 - ll_baseline, '\\n')\n",
    "    # return ll_baseline, ll_model1, ll_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish processing data!\n",
      "neo125m_k100:  613.9199054753408\n",
      "neo125m_k1000:  652.7866566646844 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "main('neo125m', 'k100', 'neo125m', 'k1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PTSA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
